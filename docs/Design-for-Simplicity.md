#   Design for Simplicity

The portable Parser Expression Grammar system pPEG aims to be as simple as possible. To do this several features that are provided by other grammar parser systems are not supported in pPEG. The lack of these features does not result in any significant loss of either grammar expressive power or performance.

The benefits of simplicity far outweigh any loss of function. If the lack of functionality ever becomes an issue then pPEG has an extension feature that can be used as an escape hatch to do whatever is required. Of course this escape hatch could be abused, but limited extensions do not cause any problems, and most grammars found in practice do not require any extensions.

Now for a list of things that pPEG does not do:

##	No Ambiguity

A pPEG is a form of PEG with committed choices that can only define unambiguous grammars.  Most computer languages, protocols, and data structure specifications, are unambiguous by design, so this is a positive advantage and not a limitation.  

Traditional grammar specifications use a Context Free Grammar or CFG, and these grammars can be ambiguous.   That means the grammar can derive the same string in more than one way. There is no known example of a CFG  grammar that can not be expressed with a PEG grammar, but there are examples of PEG grammars that can not be expressed as a CFG.

There are however some applications, such as natural language processing, that do need ambiguity. For these applications a PEG is not suitable. There are many good grammar parser generators, for example [GLL parsing] that extends the advantage of a PEG style recursive descent parsing to include ambiguous grammars.

[GLL parsing]: https://www.sciencedirect.com/science/article/pii/S1571066110001209

##	No Lexical Scanner

Traditional parsers employ a lexical scanner as a pre-processor to generate a token stream for the parser to process.   This may simplify program implementation and help performance, but it complicates the user’s model because two separate grammars are required, one for the lexical tokens and another for the main grammar. 

PEG grammar rules integrate the lexical matching rules into a single grammar. This integration also provides some extra expressive power in that lexical rules can be applied more selectively. This flexibility is difficult to provide with a separate lexical scanner.


##	No Semantic Actions

Some parsers allow grammar rules to be extended with semantic actions that can transform the results generated by grammar rules. This is a powerful feature, but it conflates the grammar rules with processing instructions using a general purpose programming language. 

To keep the grammar clean and portable the pPEG grammar does not support semantic actions. The parser builds a parse tree from the grammar before any semantic actions are applied. The semantic actions are implemented as parse tree transformations. 

However, in rare cases a semantic action may be essential to the operation of the parser.  If the parser really requires semantic actions then either the grammar is poorly designed, or the syntax is so complicated that it can not be expressed with PEG (or CFG) rules.  This can happen occasionally and the pPEG extension feature can be used to deal with these gnarly grammars [see pPEG context sensitive grammars].

[see pPEG context sensitive grammars]: https://github.com/pcanz/pPEG/blob/master/docs/context-sensitive-grammars.md

Semantic actions may also be used to improve performance, and if required pPEG extensions can be used for that as well. 

In fact pPEG extensions can do anything that a semantic action can do.  It boils down to the philosophy.  Semantic actions are seen as an integral part of the grammar. In contrast, grammar extensions in pPEG are thought of as exceptions that are only employed when there is no other option.

Most semantic actions are much better implemented as parse tree transform functions that are applied after a parse tree has been generated.


##	No Packrat Memos

A PEG grammar can achieve linear O(n) performance if it keeps memos for rule results to avoid re-parsing the same input more than once. Unfortunately this can result in explosive memory usage, but fortunately packrat memos are rarely required in practice. 

PEG grammar rules can almost always be rewritten to avoid the need for packrat memos. As a simple example:

	s = x y / x z

This rule requires the `x` to be parsed twice to match the second alternative, but it can be rewritten as:

	s = x (y / z)

Another example, a traditional CFG rule for a list might be expressed as:

	list = item “ , “ list | item

But idiomatic PEG would instead write it as:

	list = item (“ , “ item)*

This generates a flat list (no recursion) without the need to backtrack and re-parse the same `item`. Idiomatic PEG grammars employ rules that naturally avoid the need for memos. 

In theory packrat memos are needed to avoid exponential performance.  But in practice this is not an issue.  If it ever becomes necessary a pPEG extension can be used to provide memos for selected results.


##	No AST

A parser for a grammar generates a parse tree from an input string.  By tradition a grammar defines productions for the syntax of all valid strings in the language that the grammar defines.  In theory a parse tree is a derivation from a grammar in the form of an AST (Abstract Syntax Tree).

In practice a parser may not generate an ideal AST, instead it generates a CST (Concrete Syntax Tree) which can be manicured and transformed into an AST. In a compiler there can be a pipeline with many stages of tree transformation before finally translating an AST into compiled code.

In contrast, PEG grammar rules are syntax pattern recognizers. A parser can execute the grammar rules directly as instructions to match against an input string and generate a parse tree. The focus of the grammar design is on pattern matching of the input string rather than on derivation of an AST. 

A pPEG parser further interprets the grammar rules names as semantic tags, and generates a Semantic Tag Tree or STT.  The STT is a semantic markup of the input string. Grammar rules define the syntax for text that represents a value for a semantic type labelled with the rule name.

A pPEG grammar is designed to generate a STT with semantic data types that an application can transform into an AST, or some other data structure that suits the application. A pPEG grammar can be written to define a minimal SST that eliminates redundant information. 

Literals and anonymous grammar rules are used to match segments of the input string that are not required as part of the text that is the value of a semantic element. 

Terminal grammar rules that directly match segments of the input text generate STT leaf nodes with the rule name as a semantic tag that denotes the meaning of the matched text. In programming language terms this represents a wrapper type for a text string value.

A grammar rule that matches a sequence of sub-elements generates an STT node that has the form of a functional expression.  The rule name is a semantic tag that appears as a prefix function with arguments that are component sub-trees.

For example, for this simple date grammar:

    date  = year ‘-‘ month ‘-‘ day
    year  = [0-9]*4 
    month = [0-9]*2 
    day   = [0-9]*2 

The results from parsing the input “2022-03-04” as a Lisp s-expression:

	(date (year “2022”) (month “03”) (day “04”))

The s-expression format can be interpreted as a semantic `date` function with three arguments.

Or in JSON format:

	[“date”, [“year”, “2022”], [“month”, “03”], [“day”, “04"]]

An application can define a function for the `date` tag to translate the date  into a programming language data  type.

The previous s-expression or JSON formats are useful ways to display the STT in a human readable format.  However, the underlying implementation of the STT is expected to contain index pointers into the input string.

For example:

	{ tag: “date”, start: 0, end: 10,  args: [
		{ tag: “year”, start: 0, end: 4, args: [] },
		{ tag: “month”, start: 5, end: 7, args: [] },
		{ tag: “day”, start: 8, end: 10, args: [] }
    ]}
	
This allows applications to relate STT nodes back to the full input text that they were derived from. This is useful for text transformation applications and for error reporting.

The internal SST data structure can be implemented in different ways to suit the host programming language.  An s-expression or a JSON format can provides a portable representation that is independent of the programming language and implementation details.

An s-expression with full SST information:

	(date 0 10 (year “2022”) (month “03”) (day “04”))

Or in JSON format:

	[“date”, 0, 10, [“year”, “2022”], [“month”, “03”], [“day”, “04"]]

In summary, a pPEG parser generates a STT, rather than an AST (or CST). A STT is a simplified parse tree that applies the grammar rule names as semantic tags.  This creates a semantic markup of the input text that can be used to represent programming language data types.


##	No Left Recursion

Left recursion is quite common in traditional grammar specifications, but this is not possible in a standard PEG specification, although there are algorithms that can extend a PEG with left recursion.

Left recursion can always be removed by rewriting the grammar, for example:

	exp = exp op term / term

In pPEG this would be written as:

	exp = term (op term)*

Some people find left recursion very expressive and believe that the PEG version is a poor substitute.  This opinion seems to boil down to the fact that the left recursion shows that the expression is left associative.

In a pPEG grammar the rule name is a semantic tag to denote the meaning of the matched text, and that includes whether the operator is left or right associative, or neither.

A pPEG parser generates a parse tree in the form of a Semantic Tag Tree, or STT. The rule result is a flat list of terms with the rule name as a prefix in the form of a function expression:

	add = term (‘+’ term)*   =>  (add term term term …)  =>  (+ 1 2 3)

The nodes in an STT are in the form of a function with multiple arguments, rather than the traditional binary operator tree for infix operators.

The functional form is very versatile and the semantic tag (rule name) can be implemented with a function that evaluates the form in many different ways. It may be left (or right) associative and reduce the list with a reduce or fold function, but it can evaluate the from in any way required.

For example:

    lt = a < b < c  => (lt a b c) => (< 1 2 3) => 1<2 & 2<3 & 3<4 => true

Programming languages that support this kind of expression include Python, Julia, Racket, and others.

Another example:

	if = 'if' p x y   =>  (if p x y)  => x if p, else y

The `if` function evaluates either `x` or `y` but not both.

A left recursive grammar rule works well for left associative binary infix operators, but the more general functional form is uniform and flexible.  In a pPEG left associativity is determined by the semantics that the rule name denotes, rather than the form of the grammar rule.  

However, a pPEG grammar needs a rule for every operator (or maybe a group of operators) since the operator defines the semantics. But if the grammar has a very large number of operators then the number of grammar rules can become excessive.  In this case the solution is to simplify the grammar to match a sequence of many different operators and operands, and then use a Pratt algorithm to transform the list:

	exp = term (op term)*   =>  (exp term op term op term …)

     =>  (exp 1 + 2 * 3)  =>  (+ 1 (* 2 3))

For the details [see pPEG operator expressions].

[see pPEG operator expressions]: https://github.com/pcanz/pPEG/blob/master/docs/operator-expressions.md


##	No Regex

It is very tempting to extend PEG rules with regex matching. This is attractive because of the power and raw speed of a regex matcher.  But this introduces significant complications, so for simplicity pPEG does not support regex elements directly, although a custom extension can always be used to apply a regex if that is every required.

Using a regex introduces conceptual problems because a regex supports nondeterministic backtracking while PEG expressions do not.  For example, a regex could match a file name at the end of a file path like this:

	path = .*/(.+)  where a . dot represents any char

The equivalent expression as a PEG does not work: 

    path = any* ‘/‘ file     # won't work
    file = any+
    any  = ~[]

Matching any character any number of times will match all the remaining input text and leave nothing else to match . This is because a PEG makes a committed choice and can not backtrack in the way a regex can. But a PEG can use unlimited look-ahead before making a committed choice.

In a pPEG it would be expressed like this:

    path = (~[/]* ‘/‘)* file
    file = ~[]+

A regex also adds further complexity because of the cryptic syntax and the many different extensions and variations offered by different regex implementations.

A regex can be very fast, but there is no fundamental reason why a pPEG parser can not be equally competitive.


##	Summary

The pPEG grammar has been kept as simple as possible by not supporting many features provided by other grammar parser systems. But there is very little down-side to this simplicity, there is no significant loss of grammar expressive power or parser performance.
 

